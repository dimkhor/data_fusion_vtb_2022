{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def main():\n",
    "    data, output_path = sys.argv[1:]\n",
    "    transactions = pd.read_csv(f'{data}/transactions.csv')\n",
    "    transactions['transaction_dttm'] = pd.to_datetime(transactions['transaction_dttm'])\n",
    "    transactions['hour']=transactions.transaction_dttm.dt.hour\n",
    "    transactions['dow']=transactions.transaction_dttm.dt.dayofweek\n",
    "    transactions['month']=transactions.transaction_dttm.dt.month\n",
    "    transactions['date']=transactions.transaction_dttm.dt.date\n",
    "    transactions['hour_minute']=transactions.transaction_dttm.dt.strftime('%H:%M')\n",
    "\n",
    "    def is_not_rub(row):\n",
    "        if row.currency_rk in [50,60]:\n",
    "            return(1)\n",
    "        else:\n",
    "            return(0)\n",
    "    transactions['not_rub']=transactions.apply(lambda row: is_not_rub(row),axis=1)\n",
    "    foreign_currency=transactions[['user_id','not_rub']]\n",
    "    foreign_currency=foreign_currency.drop_duplicates()\n",
    "    foreign_currency.index=foreign_currency['user_id']\n",
    "    foreign_currency=foreign_currency.drop('user_id', axis=1)\n",
    "    agg_func={'not_rub':['max']}\n",
    "    foreign_currency=foreign_currency.groupby('user_id').agg(agg_func)\n",
    "    foreign_currency.columns=['not_rub']\n",
    "    \n",
    "    agg_func={'hour_minute':['nunique']}\n",
    "    transactions_minutes=transactions.groupby(['user_id','date','dow']).agg(agg_func)\n",
    "    transactions_minutes.columns=['nunique']\n",
    "    transactions_minutes=pd.pivot_table(transactions_minutes,index='user_id',columns='dow',values='nunique',aggfunc='mean').fillna(0)\n",
    "    transactions_minutes.columns=['avg_uniq_minutes_per_day_'+str(i)+'_tr'  for i in transactions_minutes.columns]\n",
    "\n",
    "    agg_func={'transaction_amt':['sum','mean','max','min']}\n",
    "    transactions_agg=transactions.groupby(['user_id','month']).agg(agg_func)\n",
    "    transactions_agg=transactions_agg.groupby(['user_id']).agg('mean')\n",
    "    transactions_agg.columns=['_'.join(col).strip()+'_by_month' for col in transactions_agg.columns.values]\n",
    "    \n",
    "    transactions['date_shift']=transactions.groupby(['user_id','mcc_code'])['date'].shift(1)\n",
    "    transactions[['date','date_shift']] = transactions[['date','date_shift']].apply(pd.to_datetime) #if conversion required\n",
    "    transactions['date_diff'] = (transactions['date'] - transactions['date_shift']).dt.days\n",
    "    transactions_calc=transactions[['user_id','mcc_code','date','date_shift','date_diff']]\n",
    "    transactions_calc=transactions_calc.drop_duplicates()\n",
    "    transactions_calc=transactions_calc.dropna()\n",
    "    transactions_calc=pd.pivot_table(transactions_calc,index='user_id',columns='mcc_code',values='date_diff',aggfunc='mean').fillna(0)\n",
    "    transactions_calc.columns=[str(i)+'_avg_date_diff'+'_tr'  for i in transactions_calc.columns]\n",
    "    \n",
    "    tr_h=pd.pivot_table(transactions,index='user_id',columns='hour',values='transaction_amt',aggfunc='count').fillna(0)\n",
    "    tr_h['summ']=tr_h.sum(axis=1)\n",
    "    for i in tr_h.columns[:-1]:\n",
    "        tr_h[i]/=tr_h['summ']\n",
    "    tr_h.columns=['prc_h_tr_'+str(i) for i in tr_h.columns]\n",
    "    tr_h=tr_h.rename(columns={'prc_h_tr_summ':'summ'})\n",
    "    tr_h=tr_h.drop(['summ'],axis=1)\n",
    "\n",
    "    tr_dow=pd.pivot_table(transactions,index='user_id',columns='dow',values='transaction_amt',aggfunc='count').fillna(0)\n",
    "    tr_dow['summ']=tr_dow.sum(axis=1)\n",
    "    for i in tr_dow.columns[:-1]:\n",
    "        tr_dow[i]/=tr_dow['summ']\n",
    "    tr_dow.columns=['prc_dow_tr_'+str(i) for i in tr_dow.columns]\n",
    "    tr_dow=tr_dow.rename(columns={'prc_dow_tr_summ':'summ'})\n",
    "    tr_dow=tr_dow.drop(['summ'],axis=1)\n",
    "\n",
    "    bankclient_embed = transactions.pivot_table(index = 'user_id', \n",
    "                             values=['transaction_amt'],\n",
    "                             columns=['mcc_code'],\n",
    "                             aggfunc=['sum','mean', 'count']).fillna(0)\n",
    "\n",
    "    bankclient_embed.columns = ['tr-'+f'{str(i[0])}-{str(i[2])}' for i in bankclient_embed.columns]\n",
    "    \n",
    "    clickstream = pd.read_csv(f'{data}/clickstream.csv')\n",
    "    clickstream.timestamp=pd.to_datetime(clickstream.timestamp)\n",
    "    clickstream['hour']=clickstream.timestamp.dt.hour\n",
    "    clickstream['dow']=clickstream.timestamp.dt.dayofweek\n",
    "    clickstream['date']=clickstream.timestamp.dt.date\n",
    "    clickstream['hour_minute']=clickstream.timestamp.dt.strftime('%H:%M')\n",
    "\n",
    "    agg_func={'new_uid':['nunique']}\n",
    "    clickstream_unq_device=clickstream.groupby(['user_id']).agg(agg_func)\n",
    "    clickstream_unq_device.columns=['cnt_unq_device_cl']\n",
    "    \n",
    "    agg_func={'hour_minute':['nunique']}\n",
    "    clickstream_minutes=clickstream.groupby(['user_id','date','dow']).agg(agg_func)\n",
    "    clickstream_minutes.columns=['nunique']\n",
    "    clickstream_minutes=pd.pivot_table(clickstream_minutes,index='user_id',columns='dow',values='nunique',aggfunc='mean').fillna(0)\n",
    "    clickstream_minutes.columns=['avg_uniq_minutes_per_day_'+str(i)+'_cl'  for i in clickstream_minutes.columns]\n",
    "\n",
    "    clickstream['date_shift']=clickstream.groupby(['user_id','cat_id'])['date'].shift(1)\n",
    "    clickstream[['date','date_shift']] = clickstream[['date','date_shift']].apply(pd.to_datetime) #if conversion required\n",
    "    clickstream['date_diff'] = (clickstream['date'] - clickstream['date_shift']).dt.days\n",
    "    clickstream_calc=clickstream[['user_id','cat_id','date','date_shift','date_diff']]\n",
    "    clickstream_calc=clickstream_calc.drop_duplicates()\n",
    "    clickstream_calc=clickstream_calc.dropna()\n",
    "    clickstream_calc=pd.pivot_table(clickstream_calc,index='user_id',columns='cat_id',values='date_diff',aggfunc='mean').fillna(0)\n",
    "    clickstream_calc.columns=[str(i)+'_avg_date_diff'+'_cl'  for i in clickstream_calc.columns]\n",
    "\n",
    "    cl_h=pd.pivot_table(clickstream,index='user_id',columns='hour',values='timestamp',aggfunc='count').fillna(0)\n",
    "    cl_h['summ']=cl_h.sum(axis=1)\n",
    "    for i in cl_h.columns[:-1]:\n",
    "        cl_h[i]/=cl_h['summ']\n",
    "    cl_h.columns=['prc_h_cl_'+str(i) for i in cl_h.columns]\n",
    "    cl_h=cl_h.rename(columns={'prc_h_cl_summ':'summ'})\n",
    "    cl_h=cl_h.drop(['summ'],axis=1)\n",
    "    \n",
    "    cl_dow=pd.pivot_table(clickstream,index='user_id',columns='dow',values='timestamp',aggfunc='count').fillna(0)\n",
    "    cl_dow['summ']=cl_dow.sum(axis=1)\n",
    "    for i in cl_dow.columns[:-1]:\n",
    "        cl_dow[i]/=cl_dow['summ']\n",
    "    cl_dow.columns=['prc_dow_cl_'+str(i) for i in cl_dow.columns]\n",
    "    cl_dow=cl_dow.rename(columns={'prc_dow_cl_summ':'summ'})\n",
    "    cl_dow=cl_dow.drop(['summ'],axis=1)\n",
    "\n",
    "    clickstream_embed = clickstream.pivot_table(index = 'user_id', \n",
    "                             values=['timestamp'],\n",
    "                             columns=['cat_id'],\n",
    "                             aggfunc=['count']).fillna(0)\n",
    "\n",
    "    clickstream_embed.columns = ['cl-'+f'{str(i[0])}-{str(i[2])}' for i in clickstream_embed.columns]\n",
    "\n",
    "    transactions=transactions.sort_values(by=['user_id','transaction_dttm'],ascending=True)\n",
    "    clickstream=clickstream.sort_values(by=['user_id','timestamp'],ascending=True)\n",
    "    transactions_wv=transactions\n",
    "    clickstream_wv=clickstream\n",
    "\n",
    "    tr_vectors_df=pd.read_csv('tr_vectors.csv')\n",
    "    cl_vectors_df=pd.read_csv('cl_vectors.csv')\n",
    "    \n",
    "    tr_vectors_df.set_index('user_id', inplace=True)\n",
    "    cl_vectors_df.set_index('user_id', inplace=True)\n",
    "    \n",
    "    del transactions\n",
    "    del clickstream\n",
    "    \n",
    "    list_of_rtk = list(clickstream_embed.index.unique())\n",
    "    list_of_bank= list(bankclient_embed.index.unique())\n",
    "    \n",
    "    submission = pd.DataFrame(list_of_bank, columns=['bank'])\n",
    "    submission['rtk'] = submission['bank'].apply(lambda x: list_of_rtk)\n",
    "\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model('data_fusion_matching_6.cbm',  format='cbm')\n",
    "    \n",
    "    full_list_of_features=model.feature_names_\n",
    "    \n",
    "    submission_ready = []\n",
    "\n",
    "    batch_size = 200\n",
    "    num_of_batches = int((len(list_of_bank))/batch_size)+1\n",
    "\n",
    "    for i in range(num_of_batches):\n",
    "        bank_ids = list_of_bank[(i*batch_size):((i+1)*batch_size)]\n",
    "        if len(bank_ids) != 0:\n",
    "            part_of_submit = submission[submission['bank'].isin(bank_ids)].explode('rtk')\n",
    "            part_of_submit = part_of_submit.merge(bankclient_embed, how='left', left_on='bank', right_index=True)\\\n",
    "               .merge(clickstream_embed, how='left', left_on='rtk', right_index=True)\\\n",
    "               .merge(tr_dow, how='left', left_on='bank', right_index=True)\\\n",
    "               .merge(tr_h, how='left', left_on='bank', right_index=True)\\\n",
    "               .merge(transactions_agg, how='left', left_on='bank', right_index=True)\\\n",
    "               .merge(transactions_minutes, how='left', left_on='bank', right_index=True)\\\n",
    "               .merge(transactions_calc, how='left', left_on='bank', right_index=True)\\\n",
    "               .merge(foreign_currency, how='left', left_on='bank', right_index=True)\\\n",
    "               .merge(cl_dow, how='left', left_on='rtk', right_index=True)\\\n",
    "               .merge(cl_h, how='left', left_on='rtk', right_index=True)\\\n",
    "               .merge(clickstream_minutes, how='left', left_on='rtk', right_index=True)\\\n",
    "               .merge(clickstream_calc, how='left', left_on='bank', right_index=True)\\\n",
    "               .merge(clickstream_unq_device, how='left', left_on='rtk', right_index=True)\\\n",
    "               .merge(tr_vectors_df, how='left', left_on='bank', right_index=True)\\\n",
    "               .merge(cl_vectors_df, how='left', left_on='rtk', right_index=True)\\\n",
    "               .fillna(0)\n",
    "        \n",
    "            for i in full_list_of_features:\n",
    "                if i not in part_of_submit.columns:\n",
    "                    part_of_submit[i] = 0\n",
    "            \n",
    "\n",
    "            part_of_submit['predicts'] = model.predict_proba(part_of_submit[full_list_of_features])[:,1]\n",
    "            part_of_submit = part_of_submit[['bank', 'rtk', 'predicts']]\n",
    "\n",
    "            zeros_part = pd.DataFrame(bank_ids, columns=['bank'])\n",
    "            zeros_part['rtk'] = 0.\n",
    "            zeros_part['predicts'] = 0.8\n",
    "            \n",
    "            part_of_submit = pd.concat((part_of_submit, zeros_part))\n",
    "\n",
    "            part_of_submit = part_of_submit.sort_values(by=['bank', 'predicts'], ascending=False).reset_index(drop=True)\n",
    "            part_of_submit = part_of_submit.pivot_table(index='bank', values='rtk', aggfunc=list)\n",
    "            part_of_submit['rtk'] = part_of_submit['rtk'].apply(lambda x: x[:100])\n",
    "            part_of_submit['bank'] = part_of_submit.index\n",
    "            part_of_submit = part_of_submit[['bank', 'rtk']]\n",
    "            submission_ready.extend(part_of_submit.values)\n",
    "    \n",
    "    submission_final = np.array(submission_ready, dtype=object)\n",
    "\n",
    "    print(submission_final.shape)\n",
    "    np.savez(output_path, submission_final)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6-default",
   "language": "python",
   "name": "py36-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
